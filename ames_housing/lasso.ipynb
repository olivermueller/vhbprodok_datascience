{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ames Housing - LASSO (Least Absolute Shrinkage and Selection Operator)\n",
    "- Author: Oliver Mueller\n",
    "- Last update: 26.01.2024"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize notebook\n",
    "Load required packages. Set up workspace, e.g., set theme for plotting and initialize the random number generator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.simplefilter('ignore')\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.linear_model import LassoCV\n",
    "from sklearn.metrics import mean_squared_error, r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.style.use('fivethirtyeight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem description\n",
    "\n",
    "Ask a home buyer to describe their dream house, and they probably won't begin with the height of the basement ceiling or the proximity to an east-west railroad. But this dataset proves that much more influences price negotiations than the number of bedrooms or a white-picket fence. With 76 explanatory variables describing (almost) every aspect of residential homes in Ames, Iowa, this dataset challenges you to predict the final price of each home. More: <https://www.kaggle.com/c/house-prices-advanced-regression-techniques>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data\n",
    "\n",
    "Load training data from CSV file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('https://raw.githubusercontent.com/olivermueller/vhbprodok_datascience/main/ames_housing/data/train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we will remove some columns that are not useful for our task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.drop(['house_id', 'YrSold', 'MoSold', 'SaleCondition', 'SaleType'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we will split the data into features (*X*) and labels (*y*) and into training (*X_train, y_train*) and test (*X_test, y_test*) sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data.drop(\"SalePrice\", axis=1)\n",
    "y = data[\"SalePrice\"]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we will do some feature engineering. It is important to use only information from the training set for feature engineering, and the mechanistically repeat these steps on the test set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Typically, feature engineering depends strongly on the datatype of the variables. Hence, we will first determine which variables are categorical and which are numerical. Subsequentally, we will transform these variables seperately."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_features = X_train.select_dtypes(include='object').columns\n",
    "numerical_features = X_train.select_dtypes(exclude='object').columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The categorical variables must be transformed into numerical representations, e.g., by one-hot encdoing them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "enc = OneHotEncoder(handle_unknown='ignore', sparse_output=False)\n",
    "enc.fit(X_train[categorical_features])\n",
    "\n",
    "X_train_cat = enc.transform(X_train[categorical_features])\n",
    "X_test_cat = enc.transform(X_test[categorical_features])\n",
    "\n",
    "X_train_cat = pd.DataFrame(X_train_cat, columns=enc.get_feature_names_out(categorical_features))\n",
    "X_test_cat = pd.DataFrame(X_test_cat, columns=enc.get_feature_names_out(categorical_features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_cat.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The numerical variables will be standardized, that is, we will subtract the mean and divide by the standard deviation. This is especially important for LASSO, as all coefficients need to be comparable in terms of units and magnitudes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train[numerical_features]) \n",
    "\n",
    "X_train_num = scaler.transform(X_train[numerical_features])\n",
    "X_test_num = scaler.transform(X_test[numerical_features])\n",
    "\n",
    "X_train_num = pd.DataFrame(X_train_num, columns=numerical_features)\n",
    "X_test_num = pd.DataFrame(X_test_num, columns=numerical_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_num.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's fuse the enginnered categorical and numerical variables again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = pd.concat([X_train_num, X_train_cat], axis=1)\n",
    "X_test = pd.concat([X_test_num, X_test_cat], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LASSO regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will start by initializing a LASSO model with an arbitrary lambda (called *alpha* in sklearn) value and fitting it on the training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lasso_mod = Lasso(alpha=1)\n",
    "lasso_mod.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluate the model on both training and test set using *R2* and *RMSE* as metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training data\n",
    "pred_train = lasso_mod.predict(X_train)\n",
    "r2_train = r2_score(y_train, pred_train)\n",
    "rmse_train = mean_squared_error(y_train, pred_train, squared=False)\n",
    "print('R2 on training set:', round(r2_train, 2))\n",
    "print('RMSE on training set:', round(rmse_train, 2))\n",
    "\n",
    "print(\"===\")\n",
    "\n",
    "# Test data\n",
    "pred_test = lasso_mod.predict(X_test)\n",
    "r2_test = r2_score(y_test, pred_test)\n",
    "rmse_test = mean_squared_error(y_test, pred_test, squared=False)\n",
    "print('R2 on test set:', round(r2_test, 2))\n",
    "print('RMSE on test set:', round(rmse_test, 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we will try 100 different lambda (*alpha*) values between 0 and 1000. The loop below fits 100 different LASSO models, each with a different alpha, and collects the test set RMSE and the estimated coefficients in a dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alphas = np.linspace(0, 1000, 100)\n",
    "\n",
    "lasso_mod = Lasso()\n",
    "\n",
    "results = []\n",
    "for a in alphas:\n",
    "    result = {}\n",
    "    lasso_mod.set_params(alpha=a)\n",
    "    lasso_mod.fit(X_train, y_train)\n",
    "    pred_test = lasso_mod.predict(X_test)\n",
    "\n",
    "    rmse_test = mean_squared_error(y_test, pred_test, squared=False)\n",
    "    \n",
    "    coef_names = lasso_mod.feature_names_in_\n",
    "    coef_values = lasso_mod.coef_\n",
    "\n",
    "    result[\"alpha\"] = a\n",
    "    result[\"rmse\"] = rmse_test\n",
    "    for i in range(0, len(coef_names)):\n",
    "        result[coef_names[i]] = coef_values[i]\n",
    "\n",
    "    results.append(result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df = pd.DataFrame(results)\n",
    "results_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's visualize how the coefficients shrink with increasing alpha."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# wrangle the data into long format\n",
    "results_df_long = pd.melt(results_df.drop(['alpha', 'rmse'], axis=1), value_vars=results_df.columns[2:])\n",
    "alphas_m = np.tile(results_df[\"alpha\"].to_numpy(), 283)\n",
    "rmses_m = np.tile(results_df[\"rmse\"].to_numpy(), 283)\n",
    "results_df_long[\"alpha\"] = alphas_m\n",
    "results_df_long[\"rmse\"] = rmses_m\n",
    "\n",
    "# create lineplot\n",
    "sns.lineplot(data=results_df_long, x=results_df_long[\"alpha\"], y=results_df_long[\"value\"], hue=results_df_long[\"variable\"])\n",
    "plt.xscale('log')\n",
    "plt.xlabel('alpha')\n",
    "plt.ylabel('Standardized Coefficients')\n",
    "plt.legend().remove()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similarily, we can plot the test set RMSE against alpha."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.lineplot(data=results_df_long, x=results_df_long[\"alpha\"], y=results_df_long[\"rmse\"])\n",
    "plt.xlabel('alpha')\n",
    "plt.ylabel('RMSE')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameter tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A more robust way to choose the alpha value that leads to the best out-of-sample predictive accuracy is to use k-fold cross validation (we might just have been lucky with the above train/test split)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lasso_mod_cv = LassoCV(cv=5, alphas=alphas, random_state=42)\n",
    "lasso_mod_cv.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Which alpha value leads to the best out-of-sample predictive accuracy?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lasso_mod_cv.alpha_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Refit the model with the best alpha value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lasso_mod_tuned = Lasso(alpha=lasso_mod_cv.alpha_)\n",
    "lasso_mod_tuned.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluate this model on the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training data\n",
    "pred_train = lasso_mod_tuned.predict(X_train)\n",
    "r2_train = r2_score(y_train, pred_train)\n",
    "rmse_train = mean_squared_error(y_train, pred_train, squared=False)\n",
    "print('R2 on training set:', round(r2_train, 2))\n",
    "print('RMSE on training set:', round(rmse_train, 2))\n",
    "\n",
    "print(\"===\")\n",
    "\n",
    "# Test data\n",
    "pred_test = lasso_mod_tuned.predict(X_test)\n",
    "r2_test = r2_score(y_test, pred_test)\n",
    "rmse_test = mean_squared_error(y_test, pred_test, squared=False)\n",
    "print('R2 on test set:', round(r2_test, 2))\n",
    "print('RMSE on test set:', round(rmse_test, 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A secret weapon: LASSO with A LOT OF interaction terms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The automatic feature selection capability of LASSO can be used to identify important interaction terms. In the following, we will add all possible interaction terms to the feature matrix, use cross-validation to identify the best lambda/alpha value, and then refit and evaluate a final model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check dimensions of *X_train*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the *PolynomialFeatures* transformer to create all possible two-way combinations of features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interact = PolynomialFeatures(interaction_only=True)\n",
    "\n",
    "X_train_interact = interact.fit_transform(X_train)\n",
    "X_train_interact = pd.DataFrame(X_train_interact, columns=interact.get_feature_names_out())\n",
    "\n",
    "X_test_interact = interact.transform(X_test)\n",
    "X_test_interact = pd.DataFrame(X_test_interact, columns=interact.get_feature_names_out())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check dimensions of *X_train_interact*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_interact.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's have a look at the feature matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_interact.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As done before, we now perform k-fold cross validation to search for best lambda/alpha value and then refit the model with this parameter. WARNING: The next cell might take a while to run (approx. 15mins)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alphas = np.linspace(0, 10000, 100)\n",
    "lasso_mod_interact_cv = LassoCV(cv=2, alphas=alphas, random_state=42)\n",
    "lasso_mod_interact_cv.fit(X_train_interact, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lasso_mod_interact_tuned = Lasso(alpha=lasso_mod_interact_cv.alpha_)\n",
    "lasso_mod_interact_tuned.fit(X_train_interact, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluate the tuned LASSO model with all possible two-way interactions on the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training data\n",
    "pred_train = lasso_mod_interact_tuned.predict(X_train_interact)\n",
    "r2_train = r2_score(y_train, pred_train)\n",
    "rmse_train = mean_squared_error(y_train, pred_train, squared=False)\n",
    "print('R2 on training set:', round(r2_train, 2))\n",
    "print('RMSE on training set:', round(rmse_train, 2))\n",
    "\n",
    "print(\"===\")\n",
    "\n",
    "# Test data\n",
    "pred_test = lasso_mod_interact_tuned.predict(X_test_interact)\n",
    "r2_test = r2_score(y_test, pred_test)\n",
    "rmse_test = mean_squared_error(y_test, pred_test, squared=False)\n",
    "print('R2 on test set:', round(r2_test, 2))\n",
    "print('RMSE on test set:', round(rmse_test, 2))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "prodok",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
