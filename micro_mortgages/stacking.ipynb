{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Micro Mortgages - Stacking\n",
    "- Author: Oliver Mueller\n",
    "- Last update: 26.01.2024"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize notebook\n",
    "Load required packages. Set up workspace, e.g., set theme for plotting and initialize the random number generator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.simplefilter('ignore')\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier, plot_tree\n",
    "from sklearn import tree\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import HistGradientBoostingClassifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.style.use('fivethirtyeight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem description\n",
    "\n",
    "In India, there are about 20 million home loan (mortgage) aspirants\n",
    "working in the informal sector:\n",
    "\n",
    "- Monthly income between INR 20,000-25,000 (\\$ 325-400)\n",
    "- Typically no formal accounts and documents (e.g., tax returns, income proofs, bank statements)\n",
    "- Often use services of money lenders with interest rates between 30 and 60% per annum\n",
    "\n",
    "Providing mortgages to this group of customers requires to quickly and\n",
    "efficiently assess their creditworthiness. Due to a lack of formal\n",
    "documents and objective data, most financial institutions perform\n",
    "interview-based processes to decide about these loan requests:\n",
    "\n",
    "Strength of the current process:\n",
    "\n",
    "-   Interview-based field assessment\n",
    "\n",
    "-   Relaxation of document requirements\n",
    "\n",
    "Weaknesses of the current process:\n",
    "\n",
    "-   Costly (total transaction costs as high as 30% of loan volume)\n",
    "\n",
    "-   Subjective judgments; depends on individual skills and motivations\n",
    "\n",
    "-   Low reliability across branches and credit officers\n",
    "\n",
    "-   Risk of corruption and fraud"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data\n",
    "\n",
    "Load training data from CSV file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('https://raw.githubusercontent.com/olivermueller/vhbprodok_datascience/main/micro_mortgages/data/micromortgage.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.drop(['ID'], axis=1)\n",
    "data[\"Tier\"] = data[\"Tier\"].apply(lambda x: \"T\"+str(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data.drop(\"Decision\", axis=1)\n",
    "y = data[\"Decision\"]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_features = X_train.select_dtypes(include='object').columns\n",
    "numerical_features = X_train.select_dtypes(exclude='object').columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numerical_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "enc = OneHotEncoder(handle_unknown='ignore', sparse_output=False)\n",
    "enc.fit(X_train[categorical_features])\n",
    "\n",
    "X_train_cat = enc.transform(X_train[categorical_features])\n",
    "X_test_cat = enc.transform(X_test[categorical_features])\n",
    "\n",
    "X_train_cat = pd.DataFrame(X_train_cat, columns=enc.get_feature_names_out(categorical_features))\n",
    "X_test_cat = pd.DataFrame(X_test_cat, columns=enc.get_feature_names_out(categorical_features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_cat.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train[numerical_features]) \n",
    "\n",
    "X_train_num = scaler.transform(X_train[numerical_features])\n",
    "X_test_num = scaler.transform(X_test[numerical_features])\n",
    "\n",
    "X_train_num = pd.DataFrame(X_train_num, columns=numerical_features)\n",
    "X_test_num = pd.DataFrame(X_test_num, columns=numerical_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_num.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = pd.concat([X_train_num, X_train_cat], axis=1)\n",
    "X_test = pd.concat([X_test_num, X_test_cat], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LASSO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_lasso_cv = lambda: GridSearchCV(\n",
    "                estimator=LogisticRegression(random_state=42),\n",
    "                param_grid={\n",
    "                        'C': np.logspace(-4, 4, 10)\n",
    "                    }, cv=5, n_jobs=-1\n",
    "                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_lasso_tuned = model_lasso_cv()\n",
    "model_lasso_tuned.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_lasso_label = model_lasso_tuned.predict(X_test)\n",
    "pred_lasso_proba = model_lasso_tuned.predict_proba(X_test)[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test, pred_lasso_label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "roc_auc_score(y_test, pred_lasso_proba)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_rf_cv = lambda: GridSearchCV(\n",
    "                estimator=RandomForestClassifier(random_state=42),\n",
    "                param_grid={\n",
    "                        'n_estimators': [100, 200, 300],\n",
    "                        'max_depth': [3, 5, None],\n",
    "                        'min_samples_leaf': [2, 5, 10]\n",
    "                    }, cv=5, n_jobs=-1\n",
    "                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_rf_tuned = model_rf_cv()\n",
    "model_rf_tuned.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_rf_label = model_rf_tuned.predict(X_test)\n",
    "pred_rf_proba = model_rf_tuned.predict_proba(X_test)[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test, pred_rf_label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "roc_auc_score(y_test, pred_rf_proba)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stack models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we will use a simple stacking approach by combining the predictions of the LASSO and Random Forest models with equal weight."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_final_proba = (pred_lasso_proba + pred_rf_proba) / 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "roc_auc_score(y_test, pred_final_proba)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "prodok",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
