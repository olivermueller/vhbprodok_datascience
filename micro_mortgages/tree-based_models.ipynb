{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Micro Mortgages - Tree-based Models\n",
    "- Author: Oliver Mueller\n",
    "- Last update: 26.01.2024"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize notebook\n",
    "Load required packages. Set up workspace, e.g., set theme for plotting and initialize the random number generator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.simplefilter('ignore')\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import roc_auc_score, roc_curve, RocCurveDisplay, auc\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier, plot_tree\n",
    "from sklearn import tree\n",
    "#import graphviz as graphviz\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import HistGradientBoostingClassifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.style.use('fivethirtyeight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem description\n",
    "\n",
    "In India, there are about 20 million home loan (mortgage) aspirants\n",
    "working in the informal sector:\n",
    "\n",
    "- Monthly income between INR 20,000-25,000 (\\$ 325-400)\n",
    "- Typically no formal accounts and documents (e.g., tax returns, income proofs, bank statements)\n",
    "- Often use services of money lenders with interest rates between 30 and 60% per annum\n",
    "\n",
    "Providing mortgages to this group of customers requires to quickly and\n",
    "efficiently assess their creditworthiness. Due to a lack of formal\n",
    "documents and objective data, most financial institutions perform\n",
    "interview-based processes to decide about these loan requests:\n",
    "\n",
    "Strength of the current process:\n",
    "\n",
    "-   Interview-based field assessment\n",
    "\n",
    "-   Relaxation of document requirements\n",
    "\n",
    "Weaknesses of the current process:\n",
    "\n",
    "-   Costly (total transaction costs as high as 30% of loan volume)\n",
    "\n",
    "-   Subjective judgments; depends on individual skills and motivations\n",
    "\n",
    "-   Low reliability across branches and credit officers\n",
    "\n",
    "-   Risk of corruption and fraud"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data\n",
    "\n",
    "Load training data from CSV file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('https://raw.githubusercontent.com/olivermueller/vhbprodok_datascience/main/micro_mortgages/data/micromortgage.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.drop(['ID'], axis=1)\n",
    "data[\"Tier\"] = data[\"Tier\"].apply(lambda x: \"T\"+str(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data.drop(\"Decision\", axis=1)\n",
    "y = data[\"Decision\"]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_features = X_train.select_dtypes(include='object').columns\n",
    "numerical_features = X_train.select_dtypes(exclude='object').columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numerical_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "enc = OneHotEncoder(handle_unknown='ignore', sparse_output=False)\n",
    "enc.fit(X_train[categorical_features])\n",
    "\n",
    "X_train_cat = enc.transform(X_train[categorical_features])\n",
    "X_test_cat = enc.transform(X_test[categorical_features])\n",
    "\n",
    "X_train_cat = pd.DataFrame(X_train_cat, columns=enc.get_feature_names_out(categorical_features))\n",
    "X_test_cat = pd.DataFrame(X_test_cat, columns=enc.get_feature_names_out(categorical_features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_cat.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train[numerical_features]) \n",
    "\n",
    "X_train_num = scaler.transform(X_train[numerical_features])\n",
    "X_test_num = scaler.transform(X_test[numerical_features])\n",
    "\n",
    "X_train_num = pd.DataFrame(X_train_num, columns=numerical_features)\n",
    "X_test_num = pd.DataFrame(X_test_num, columns=numerical_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_num.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = pd.concat([X_train_num, X_train_cat], axis=1)\n",
    "X_test = pd.concat([X_test_num, X_test_cat], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification and Regression Trees (CART)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we will grow a single CART tree."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_cart = DecisionTreeClassifier(criterion='entropy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_cart.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check how well the tree performs on the training and test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training data\n",
    "pred_label_train = model_cart.predict(X_train)\n",
    "pred_proba_train = model_cart.predict_proba(X_train)[:,1]\n",
    "acc_train = accuracy_score(y_train, pred_label_train)\n",
    "auc_train = roc_auc_score(y_train, pred_proba_train)\n",
    "print('ACC on training set:', round(acc_train, 2))\n",
    "print('AUC on training set:', round(auc_train, 2))\n",
    "\n",
    "print(\"===\")\n",
    "\n",
    "# Test data\n",
    "pred_label_test = model_cart.predict(X_test)\n",
    "pred_proba_test = model_cart.predict_proba(X_test)[:,1]\n",
    "acc_test = accuracy_score(y_test, pred_label_test)\n",
    "auc_test = roc_auc_score(y_test, pred_proba_test)\n",
    "print('ACC on training set:', round(acc_test, 2))\n",
    "print('AUC on test set:', round(auc_test, 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The advantage of a single tree is that it is easy to interpret and visualize. Let's have a look."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fn = model_cart.feature_names_in_\n",
    "labels = model_cart.classes_\n",
    "labels = [str(item) for item in labels]\n",
    "\n",
    "tree.plot_tree(model_cart, feature_names=fn, class_names=labels, filled=True, proportion=True, rounded=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wow, that's a big tree! It is hard to interpret and understand. Let's go back and try to grow a smaller tree by setting stopping rules (e.g., `max_depth`) or pruning the tree (`ccp_alpha`)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now try to grow a random forest. This time, we will use hyperparameter tuning with k-fold cross validation to find the best model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_rf_cv = lambda: GridSearchCV(\n",
    "                estimator=RandomForestClassifier(random_state=42),\n",
    "                param_grid={\n",
    "                        'n_estimators': [100, 200, 300],\n",
    "                        'max_depth': [3, 5, None],\n",
    "                        'min_samples_leaf': [2, 5, 10]\n",
    "                    }, cv=5, n_jobs=-1\n",
    "                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_rf_tuned = model_rf_cv()\n",
    "model_rf_tuned.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make predictions on test set and evaluate the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_label = model_rf_tuned.predict(X_test)\n",
    "pred_proba = model_rf_tuned.predict_proba(X_test)[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test, pred_label))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot the ROC curve and calculate the AUC."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fpr, tpr, thresholds = roc_curve(y_test, pred_proba)\n",
    "auc_score = auc(fpr, tpr)\n",
    "display = RocCurveDisplay(fpr=fpr, tpr=tpr, roc_auc=auc_score, estimator_name='Random Forest')\n",
    "display.plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Boosted Trees"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we will try boosted trees. We will use the fast `HistGradientBoostingClassifier` (Histogram-based Gradient Boosting Classification Tree) learner, which is inspired by the LightGBM algorithm. Again, we will use hyperparameter tuning with k-fold cross validation to find the best model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_boost_cv = lambda: GridSearchCV(\n",
    "                estimator=HistGradientBoostingClassifier(random_state=42),\n",
    "                param_grid={\n",
    "                        'max_iter': [100, 200, 300],\n",
    "                        'max_depth': [1, 3, 5, 10]\n",
    "                    }, cv=5, n_jobs=-1\n",
    "                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_boost_tuned = model_boost_cv()\n",
    "model_boost_tuned.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_label = model_boost_tuned.predict(X_test)\n",
    "pred_proba = model_boost_tuned.predict_proba(X_test)[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test, pred_label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fpr, tpr, thresholds = roc_curve(y_test, pred_proba)\n",
    "auc_score = auc(fpr, tpr)\n",
    "display = RocCurveDisplay(fpr=fpr, tpr=tpr, roc_auc=auc_score, estimator_name='Gradient Boosting')\n",
    "display.plot()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "prodok",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
